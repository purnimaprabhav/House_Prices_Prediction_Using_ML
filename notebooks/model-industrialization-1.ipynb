{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5e11dae-a428-495c-abfc-2b39d5840e6f",
   "metadata": {},
   "source": [
    "# House Prices - Advanced Regression Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea37573c-d8c0-445e-9f1b-b17f2cc1aa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4153d2f5-676b-4ab7-8d43-97788b39dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmsle(y_test: np.ndarray, y_pred: np.ndarray, precision: int = 2) -> float:\n",
    "    y_test = np.log1p(y_test)\n",
    "    y_pred = np.log1p(y_pred)\n",
    "    \n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
    "    \n",
    "    return round(rmsle, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0caf745-3de8-4be7-99d3-bde20aaa7ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 934\n",
      "Testing set size: 234\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "train_data = pd.read_csv('/Users/purnimaprabha/dsp-purnima-prabha/house_prices/train.csv')\n",
    "test_data = pd.read_csv('/Users/purnimaprabha/dsp-purnima-prabha/house_prices/test.csv')\n",
    "\n",
    "# Select features\n",
    "numerical_features = ['GrLivArea', 'TotalBsmtSF']\n",
    "categorical_features = ['Neighborhood', 'ExterQual']\n",
    "target = 'SalePrice'\n",
    "\n",
    "# Split data first to avoid data leakage\n",
    "X = train_data[numerical_features + categorical_features]\n",
    "y = train_data[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44b7da57-da64-45d9-94cf-f85e914162cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize transformers\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "scaler = StandardScaler()\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Process numerical features\n",
    "X_train_num = X_train[numerical_features].copy()\n",
    "X_test_num = X_test[numerical_features].copy()\n",
    "\n",
    "# Fit and transform numerical features\n",
    "X_train_num_imputed = num_imputer.fit_transform(X_train_num)\n",
    "X_test_num_imputed = num_imputer.transform(X_test_num)\n",
    "\n",
    "X_train_num_scaled = scaler.fit_transform(X_train_num_imputed)\n",
    "X_test_num_scaled = scaler.transform(X_test_num_imputed)\n",
    "\n",
    "# Process categorical features\n",
    "X_train_cat = X_train[categorical_features].copy()\n",
    "X_test_cat = X_test[categorical_features].copy()\n",
    "\n",
    "# Fit and transform categorical features\n",
    "X_train_cat_imputed = cat_imputer.fit_transform(X_train_cat)\n",
    "X_test_cat_imputed = cat_imputer.transform(X_test_cat)\n",
    "\n",
    "X_train_cat_encoded = encoder.fit_transform(X_train_cat_imputed)\n",
    "X_test_cat_encoded = encoder.transform(X_test_cat_imputed)\n",
    "\n",
    "# Convert to DataFrames\n",
    "X_train_num_scaled = pd.DataFrame(X_train_num_scaled, columns=numerical_features, index=X_train.index)\n",
    "X_test_num_scaled = pd.DataFrame(X_test_num_scaled, columns=numerical_features, index=X_test.index)\n",
    "\n",
    "feature_names = encoder.get_feature_names_out(categorical_features)\n",
    "X_train_cat_encoded = pd.DataFrame(X_train_cat_encoded, columns=feature_names, index=X_train.index)\n",
    "X_test_cat_encoded = pd.DataFrame(X_test_cat_encoded, columns=feature_names, index=X_test.index)\n",
    "\n",
    "# Combine features\n",
    "X_train_processed = pd.concat([X_train_num_scaled, X_train_cat_encoded], axis=1)\n",
    "X_test_processed = pd.concat([X_test_num_scaled, X_test_cat_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f35af2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set Metrics:\n",
      "RMSLE: 0.1785\n",
      "R2 Score: 0.7669\n",
      "\n",
      "Testing Set Metrics:\n",
      "RMSLE: 0.1669\n",
      "R2 Score: -2.7666\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train_processed, y_train)\n",
    "\n",
    "def evaluate_model(X, y_true, dataset_name=\"\"):\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    if np.any(np.isnan(y_true)) or np.any(np.isnan(y_pred)):\n",
    "        valid_indices = ~np.isnan(y_true) & ~np.isnan(y_pred)\n",
    "        y_true = y_true[valid_indices]\n",
    "        y_pred = y_pred[valid_indices]\n",
    "    \n",
    "    if (y_true < 0).any() or (y_pred < 0).any():\n",
    "        y_true = np.log1p(y_true)\n",
    "        y_pred = np.log1p(y_pred)\n",
    "    \n",
    "    if np.any(np.isnan(y_true)) or np.any(np.isnan(y_pred)):\n",
    "        y_true = np.nan_to_num(y_true, nan=0)\n",
    "        y_pred = np.nan_to_num(y_pred, nan=0)\n",
    "    \n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Set Metrics:\")\n",
    "    print(f\"RMSLE: {rmsle:.4f}\")\n",
    "    print(f\"R2 Score: {r2:.4f}\")\n",
    "    return rmsle, r2\n",
    "\n",
    "train_rmsle, train_r2 = evaluate_model(X_train_processed, y_train, \"Training\")\n",
    "test_rmsle, test_r2 = evaluate_model(X_test_processed, y_test, \"Testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d9cd359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Inference\n",
    "X_test_final = test_data[numerical_features + categorical_features]\n",
    "\n",
    "# Process numerical features\n",
    "X_test_final_num = X_test_final[numerical_features].copy()\n",
    "X_test_final_num_imputed = num_imputer.transform(X_test_final_num)\n",
    "X_test_final_num_scaled = scaler.transform(X_test_final_num_imputed)\n",
    "\n",
    "# Process categorical features\n",
    "X_test_final_cat = X_test_final[categorical_features].copy()\n",
    "X_test_final_cat_imputed = cat_imputer.transform(X_test_final_cat)\n",
    "X_test_final_cat_encoded = encoder.transform(X_test_final_cat_imputed)\n",
    "\n",
    "# Convert to DataFrames and combine\n",
    "X_test_final_num_scaled = pd.DataFrame(X_test_final_num_scaled, columns=numerical_features, index=X_test_final.index)\n",
    "X_test_final_cat_encoded = pd.DataFrame(X_test_final_cat_encoded, columns=feature_names, index=X_test_final.index)\n",
    "X_test_final_processed = pd.concat([X_test_final_num_scaled, X_test_final_cat_encoded], axis=1)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test_final_processed)\n",
    "\n",
    "# Save predictions\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_data['Id'],\n",
    "    'SalePrice': predictions\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38c42acc-ab2e-4cb0-8da2-1cc6e39e790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('/Users/purnimaprabha/dsp-purnima-prabha/house_prices/train.csv')  \n",
    "processed_df = raw_df.copy()\n",
    "\n",
    "processed_df.to_parquet('/Users/purnimaprabha/dsp-purnima-prabha/processed_df.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97c3eec-ebba-48f8-a8d4-c37e5152ce97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
