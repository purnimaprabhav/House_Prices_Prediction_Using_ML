{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5e11dae-a428-495c-abfc-2b39d5840e6f",
   "metadata": {},
   "source": [
    "# House Prices - Advanced Regression Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea37573c-d8c0-445e-9f1b-b17f2cc1aa4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4153d2f5-676b-4ab7-8d43-97788b39dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmsle(y_test: np.ndarray, y_pred: np.ndarray, precision: int = 2) -> float:\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
    "    return round(rmsle, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0caf745-3de8-4be7-99d3-bde20aaa7ddf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m X = train_data[numerical_features + categorical_features]\n\u001b[32m     12\u001b[39m y = train_data[target]\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m X_train, X_test, y_train, y_test = \u001b[43mtrain_test_split\u001b[49m(X, y, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining set size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTesting set size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_test.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_data = pd.read_csv('../data/train.csv')\n",
    "test_data = pd.read_csv('../data/test.csv')\n",
    "\n",
    "# Select features\n",
    "numerical_features = ['GrLivArea', 'TotalBsmtSF']\n",
    "categorical_features = ['Neighborhood', 'ExterQual']\n",
    "target = 'SalePrice'\n",
    "\n",
    "# Split data first to avoid data leakage\n",
    "X = train_data[numerical_features + categorical_features]\n",
    "y = train_data[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44b7da57-da64-45d9-94cf-f85e914162cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize transformers\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "scaler = StandardScaler()\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Process numerical features\n",
    "X_train_num = X_train[numerical_features].copy()\n",
    "X_test_num = X_test[numerical_features].copy()\n",
    "\n",
    "# Fit and transform numerical features\n",
    "X_train_num_imputed = num_imputer.fit_transform(X_train_num)\n",
    "X_test_num_imputed = num_imputer.transform(X_test_num)\n",
    "\n",
    "X_train_num_scaled = scaler.fit_transform(X_train_num_imputed)\n",
    "X_test_num_scaled = scaler.transform(X_test_num_imputed)\n",
    "\n",
    "# Process categorical features\n",
    "X_train_cat = X_train[categorical_features].copy()\n",
    "X_test_cat = X_test[categorical_features].copy()\n",
    "\n",
    "# Fit and transform categorical features\n",
    "X_train_cat_imputed = cat_imputer.fit_transform(X_train_cat)\n",
    "X_test_cat_imputed = cat_imputer.transform(X_test_cat)\n",
    "\n",
    "X_train_cat_encoded = encoder.fit_transform(X_train_cat_imputed)\n",
    "X_test_cat_encoded = encoder.transform(X_test_cat_imputed)\n",
    "\n",
    "# Convert to DataFrames\n",
    "X_train_num_scaled = pd.DataFrame(X_train_num_scaled, columns=numerical_features, index=X_train.index)\n",
    "X_test_num_scaled = pd.DataFrame(X_test_num_scaled, columns=numerical_features, index=X_test.index)\n",
    "\n",
    "feature_names = encoder.get_feature_names_out(categorical_features)\n",
    "X_train_cat_encoded = pd.DataFrame(X_train_cat_encoded, columns=feature_names, index=X_train.index)\n",
    "X_test_cat_encoded = pd.DataFrame(X_test_cat_encoded, columns=feature_names, index=X_test.index)\n",
    "\n",
    "# Combine features\n",
    "X_train_processed = pd.concat([X_train_num_scaled, X_train_cat_encoded], axis=1)\n",
    "X_test_processed = pd.concat([X_test_num_scaled, X_test_cat_encoded], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f35af2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "\n",
      "Training Set Metrics:\n",
      "RMSLE: 0.1788\n",
      "R2 Score: 0.7779\n",
      "\n",
      "Testing Set Metrics:\n",
      "RMSLE: 0.1834\n",
      "R2 Score: 0.8199\n"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "print(\"Training model...\")\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_processed, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "def evaluate_model(X, y_true, dataset_name=\"\"):\n",
    "    y_pred = model.predict(X)\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Set Metrics:\")\n",
    "    print(f\"RMSLE: {rmsle:.4f}\")\n",
    "    print(f\"R2 Score: {r2:.4f}\")\n",
    "    return rmsle, r2\n",
    "\n",
    "# Evaluate on training and test sets\n",
    "train_rmsle, train_r2 = evaluate_model(X_train_processed, y_train, \"Training\")\n",
    "test_rmsle, test_r2 = evaluate_model(X_test_processed, y_test, \"Testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d9cd359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing test data...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_imputer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Process numerical features\u001b[39;00m\n\u001b[32m      6\u001b[39m X_test_final_num = X_test_final[numerical_features].copy()\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m X_test_final_num_imputed = \u001b[43mnum_imputer\u001b[49m.transform(X_test_final_num)\n\u001b[32m      8\u001b[39m X_test_final_num_scaled = scaler.transform(X_test_final_num_imputed)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Process categorical features\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'num_imputer' is not defined"
     ]
    }
   ],
   "source": [
    "# Model Inference\n",
    "print(\"\\nProcessing test data...\")\n",
    "X_test_final = test_data[numerical_features + categorical_features]\n",
    "\n",
    "# Process numerical features\n",
    "X_test_final_num = X_test_final[numerical_features].copy()\n",
    "X_test_final_num_imputed = num_imputer.transform(X_test_final_num)\n",
    "X_test_final_num_scaled = scaler.transform(X_test_final_num_imputed)\n",
    "\n",
    "# Process categorical features\n",
    "X_test_final_cat = X_test_final[categorical_features].copy()\n",
    "X_test_final_cat_imputed = cat_imputer.transform(X_test_final_cat)\n",
    "X_test_final_cat_encoded = encoder.transform(X_test_final_cat_imputed)\n",
    "\n",
    "# Convert to DataFrames and combine\n",
    "X_test_final_num_scaled = pd.DataFrame(X_test_final_num_scaled, columns=numerical_features, index=X_test_final.index)\n",
    "X_test_final_cat_encoded = pd.DataFrame(X_test_final_cat_encoded, columns=feature_names, index=X_test_final.index)\n",
    "X_test_final_processed = pd.concat([X_test_final_num_scaled, X_test_final_cat_encoded], axis=1)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test_final_processed)\n",
    "\n",
    "# Save predictions\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_data['Id'],\n",
    "    'SalePrice': predictions\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28485ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3995003e-b89a-4d74-86d8-42c8e6f5c29e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processed_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mprocessed_df\u001b[49m.to_parquet(\u001b[33m'\u001b[39m\u001b[33m/my/filapth/processed_df.parquet\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'processed_df' is not defined"
     ]
    }
   ],
   "source": [
    "processed_df.to_parquet('/my/filapth/processed_df.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97c3eec-ebba-48f8-a8d4-c37e5152ce97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
